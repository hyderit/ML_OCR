{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.MNIST.resources = [\n",
    "    ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz', 'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
    "    ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz', 'd53e105ee54ea40749a09fcbcd1e9432'),\n",
    "    ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz', '9fb629c4189551a2d022fa330f9573f3'),\n",
    "    ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz', 'ec29112dd5afa0611ce80d1b7f02629c')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "9920512it [00:04, 2303685.05it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "32768it [00:00, 133387.05it/s]           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "1654784it [00:00, 2021433.63it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "8192it [00:00, 40252.13it/s]            \n",
      "d:\\Anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(\n",
    "        train_data,\n",
    "        batch_size=100,\n",
    "        shuffle=True,\n",
    "        num_workers=1\n",
    "    ),\n",
    "\n",
    "    'test': DataLoader(\n",
    "        test_data,\n",
    "        batch_size=100,\n",
    "        shuffle=True,\n",
    "        num_workers=1\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders['train'].dataset)} ({100. * batch_idx / len(loaders['train']):.0f}%)]\\t{loss.item():.6f}\")\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss = loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders['test'].dataset)} ({100. * correct / len(loaders['test'].dataset):.0f}%\\n)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyder\\AppData\\Local\\Temp/ipykernel_4768/4106072696.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.302976\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t2.295396\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t2.147732\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t2.003941\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t1.893858\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t1.840765\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t1.836111\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t1.852949\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t1.826398\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t1.708540\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t1.673939\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t1.711320\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t1.688396\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t1.632332\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t1.638896\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.701706\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t1.685804\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t1.657664\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t1.642882\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t1.596866\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t1.648788\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t1.616474\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t1.615067\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t1.588786\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t1.581136\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t1.571668\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t1.674928\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t1.673372\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t1.596216\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t1.581459\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy 9347/10000 (93%\n",
      ")\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.627338\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t1.617203\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t1.635354\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t1.561488\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t1.602026\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t1.559990\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t1.567712\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t1.568906\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t1.556851\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t1.599781\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t1.590909\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t1.525609\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t1.638674\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t1.564766\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t1.567276\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.545931\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t1.555533\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t1.610339\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t1.515068\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t1.542152\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t1.530563\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t1.591709\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t1.540980\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t1.598896\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t1.587966\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t1.596792\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t1.549949\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t1.587015\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t1.536927\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t1.601552\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy 9541/10000 (95%\n",
      ")\n",
      "Train Epoch: 3 [0/60000 (0%)]\t1.551736\n",
      "Train Epoch: 3 [2000/60000 (3%)]\t1.612101\n",
      "Train Epoch: 3 [4000/60000 (7%)]\t1.541817\n",
      "Train Epoch: 3 [6000/60000 (10%)]\t1.608560\n",
      "Train Epoch: 3 [8000/60000 (13%)]\t1.607910\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t1.558755\n",
      "Train Epoch: 3 [12000/60000 (20%)]\t1.520867\n",
      "Train Epoch: 3 [14000/60000 (23%)]\t1.577225\n",
      "Train Epoch: 3 [16000/60000 (27%)]\t1.540921\n",
      "Train Epoch: 3 [18000/60000 (30%)]\t1.557964\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t1.568937\n",
      "Train Epoch: 3 [22000/60000 (37%)]\t1.535424\n",
      "Train Epoch: 3 [24000/60000 (40%)]\t1.578256\n",
      "Train Epoch: 3 [26000/60000 (43%)]\t1.583688\n",
      "Train Epoch: 3 [28000/60000 (47%)]\t1.527245\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t1.546351\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t1.530684\n",
      "Train Epoch: 3 [34000/60000 (57%)]\t1.562981\n",
      "Train Epoch: 3 [36000/60000 (60%)]\t1.571526\n",
      "Train Epoch: 3 [38000/60000 (63%)]\t1.539145\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t1.600918\n",
      "Train Epoch: 3 [42000/60000 (70%)]\t1.519226\n",
      "Train Epoch: 3 [44000/60000 (73%)]\t1.541831\n",
      "Train Epoch: 3 [46000/60000 (77%)]\t1.571585\n",
      "Train Epoch: 3 [48000/60000 (80%)]\t1.554477\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t1.529083\n",
      "Train Epoch: 3 [52000/60000 (87%)]\t1.542711\n",
      "Train Epoch: 3 [54000/60000 (90%)]\t1.524295\n",
      "Train Epoch: 3 [56000/60000 (93%)]\t1.548686\n",
      "Train Epoch: 3 [58000/60000 (97%)]\t1.560897\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy 9552/10000 (96%\n",
      ")\n",
      "Train Epoch: 4 [0/60000 (0%)]\t1.543648\n",
      "Train Epoch: 4 [2000/60000 (3%)]\t1.589461\n",
      "Train Epoch: 4 [4000/60000 (7%)]\t1.515750\n",
      "Train Epoch: 4 [6000/60000 (10%)]\t1.560106\n",
      "Train Epoch: 4 [8000/60000 (13%)]\t1.589055\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t1.531472\n",
      "Train Epoch: 4 [12000/60000 (20%)]\t1.526313\n",
      "Train Epoch: 4 [14000/60000 (23%)]\t1.560024\n",
      "Train Epoch: 4 [16000/60000 (27%)]\t1.613004\n",
      "Train Epoch: 4 [18000/60000 (30%)]\t1.570778\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t1.535516\n",
      "Train Epoch: 4 [22000/60000 (37%)]\t1.547281\n",
      "Train Epoch: 4 [24000/60000 (40%)]\t1.601415\n",
      "Train Epoch: 4 [26000/60000 (43%)]\t1.531478\n",
      "Train Epoch: 4 [28000/60000 (47%)]\t1.567050\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t1.537877\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t1.528893\n",
      "Train Epoch: 4 [34000/60000 (57%)]\t1.536659\n",
      "Train Epoch: 4 [36000/60000 (60%)]\t1.579128\n",
      "Train Epoch: 4 [38000/60000 (63%)]\t1.532435\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t1.571733\n",
      "Train Epoch: 4 [42000/60000 (70%)]\t1.582019\n",
      "Train Epoch: 4 [44000/60000 (73%)]\t1.605413\n",
      "Train Epoch: 4 [46000/60000 (77%)]\t1.555888\n",
      "Train Epoch: 4 [48000/60000 (80%)]\t1.524846\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t1.556439\n",
      "Train Epoch: 4 [52000/60000 (87%)]\t1.554761\n",
      "Train Epoch: 4 [54000/60000 (90%)]\t1.549787\n",
      "Train Epoch: 4 [56000/60000 (93%)]\t1.573292\n",
      "Train Epoch: 4 [58000/60000 (97%)]\t1.554891\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy 9623/10000 (96%\n",
      ")\n",
      "Train Epoch: 5 [0/60000 (0%)]\t1.551943\n",
      "Train Epoch: 5 [2000/60000 (3%)]\t1.565928\n",
      "Train Epoch: 5 [4000/60000 (7%)]\t1.581823\n",
      "Train Epoch: 5 [6000/60000 (10%)]\t1.502141\n",
      "Train Epoch: 5 [8000/60000 (13%)]\t1.574123\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t1.554742\n",
      "Train Epoch: 5 [12000/60000 (20%)]\t1.530225\n",
      "Train Epoch: 5 [14000/60000 (23%)]\t1.572740\n",
      "Train Epoch: 5 [16000/60000 (27%)]\t1.512843\n",
      "Train Epoch: 5 [18000/60000 (30%)]\t1.543950\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t1.521941\n",
      "Train Epoch: 5 [22000/60000 (37%)]\t1.549285\n",
      "Train Epoch: 5 [24000/60000 (40%)]\t1.572847\n",
      "Train Epoch: 5 [26000/60000 (43%)]\t1.536592\n",
      "Train Epoch: 5 [28000/60000 (47%)]\t1.518445\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t1.524493\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t1.525655\n",
      "Train Epoch: 5 [34000/60000 (57%)]\t1.553579\n",
      "Train Epoch: 5 [36000/60000 (60%)]\t1.577131\n",
      "Train Epoch: 5 [38000/60000 (63%)]\t1.544560\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t1.541073\n",
      "Train Epoch: 5 [42000/60000 (70%)]\t1.568198\n",
      "Train Epoch: 5 [44000/60000 (73%)]\t1.491115\n",
      "Train Epoch: 5 [46000/60000 (77%)]\t1.561725\n",
      "Train Epoch: 5 [48000/60000 (80%)]\t1.521521\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t1.542316\n",
      "Train Epoch: 5 [52000/60000 (87%)]\t1.554818\n",
      "Train Epoch: 5 [54000/60000 (90%)]\t1.556667\n",
      "Train Epoch: 5 [56000/60000 (93%)]\t1.560565\n",
      "Train Epoch: 5 [58000/60000 (97%)]\t1.583358\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy 9664/10000 (97%\n",
      ")\n",
      "Train Epoch: 6 [0/60000 (0%)]\t1.553331\n",
      "Train Epoch: 6 [2000/60000 (3%)]\t1.594970\n",
      "Train Epoch: 6 [4000/60000 (7%)]\t1.523318\n",
      "Train Epoch: 6 [6000/60000 (10%)]\t1.501114\n",
      "Train Epoch: 6 [8000/60000 (13%)]\t1.552364\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t1.525489\n",
      "Train Epoch: 6 [12000/60000 (20%)]\t1.539499\n",
      "Train Epoch: 6 [14000/60000 (23%)]\t1.535812\n",
      "Train Epoch: 6 [16000/60000 (27%)]\t1.578095\n",
      "Train Epoch: 6 [18000/60000 (30%)]\t1.570428\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t1.545148\n",
      "Train Epoch: 6 [22000/60000 (37%)]\t1.537178\n",
      "Train Epoch: 6 [24000/60000 (40%)]\t1.551730\n",
      "Train Epoch: 6 [26000/60000 (43%)]\t1.580691\n",
      "Train Epoch: 6 [28000/60000 (47%)]\t1.535975\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t1.581079\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t1.513734\n",
      "Train Epoch: 6 [34000/60000 (57%)]\t1.554244\n",
      "Train Epoch: 6 [36000/60000 (60%)]\t1.526784\n",
      "Train Epoch: 6 [38000/60000 (63%)]\t1.524723\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t1.526594\n",
      "Train Epoch: 6 [42000/60000 (70%)]\t1.508839\n",
      "Train Epoch: 6 [44000/60000 (73%)]\t1.509428\n",
      "Train Epoch: 6 [46000/60000 (77%)]\t1.525707\n",
      "Train Epoch: 6 [48000/60000 (80%)]\t1.515260\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t1.581008\n",
      "Train Epoch: 6 [52000/60000 (87%)]\t1.512456\n",
      "Train Epoch: 6 [54000/60000 (90%)]\t1.537394\n",
      "Train Epoch: 6 [56000/60000 (93%)]\t1.526498\n",
      "Train Epoch: 6 [58000/60000 (97%)]\t1.550113\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy 9688/10000 (97%\n",
      ")\n",
      "Train Epoch: 7 [0/60000 (0%)]\t1.519700\n",
      "Train Epoch: 7 [2000/60000 (3%)]\t1.520874\n",
      "Train Epoch: 7 [4000/60000 (7%)]\t1.518521\n",
      "Train Epoch: 7 [6000/60000 (10%)]\t1.545992\n",
      "Train Epoch: 7 [8000/60000 (13%)]\t1.531919\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t1.515760\n",
      "Train Epoch: 7 [12000/60000 (20%)]\t1.510005\n",
      "Train Epoch: 7 [14000/60000 (23%)]\t1.540907\n",
      "Train Epoch: 7 [16000/60000 (27%)]\t1.510730\n",
      "Train Epoch: 7 [18000/60000 (30%)]\t1.516160\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t1.510616\n",
      "Train Epoch: 7 [22000/60000 (37%)]\t1.566739\n",
      "Train Epoch: 7 [24000/60000 (40%)]\t1.537518\n",
      "Train Epoch: 7 [26000/60000 (43%)]\t1.524144\n",
      "Train Epoch: 7 [28000/60000 (47%)]\t1.543191\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t1.529229\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t1.557896\n",
      "Train Epoch: 7 [34000/60000 (57%)]\t1.522715\n",
      "Train Epoch: 7 [36000/60000 (60%)]\t1.533756\n",
      "Train Epoch: 7 [38000/60000 (63%)]\t1.549977\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t1.539188\n",
      "Train Epoch: 7 [42000/60000 (70%)]\t1.571445\n",
      "Train Epoch: 7 [44000/60000 (73%)]\t1.539364\n",
      "Train Epoch: 7 [46000/60000 (77%)]\t1.555715\n",
      "Train Epoch: 7 [48000/60000 (80%)]\t1.525775\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t1.549846\n",
      "Train Epoch: 7 [52000/60000 (87%)]\t1.550466\n",
      "Train Epoch: 7 [54000/60000 (90%)]\t1.522546\n",
      "Train Epoch: 7 [56000/60000 (93%)]\t1.596092\n",
      "Train Epoch: 7 [58000/60000 (97%)]\t1.578714\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy 9730/10000 (97%\n",
      ")\n",
      "Train Epoch: 8 [0/60000 (0%)]\t1.525342\n",
      "Train Epoch: 8 [2000/60000 (3%)]\t1.569848\n",
      "Train Epoch: 8 [4000/60000 (7%)]\t1.517850\n",
      "Train Epoch: 8 [6000/60000 (10%)]\t1.575741\n",
      "Train Epoch: 8 [8000/60000 (13%)]\t1.513752\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t1.501467\n",
      "Train Epoch: 8 [12000/60000 (20%)]\t1.586429\n",
      "Train Epoch: 8 [14000/60000 (23%)]\t1.536127\n",
      "Train Epoch: 8 [16000/60000 (27%)]\t1.510275\n",
      "Train Epoch: 8 [18000/60000 (30%)]\t1.547236\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t1.557401\n",
      "Train Epoch: 8 [22000/60000 (37%)]\t1.538668\n",
      "Train Epoch: 8 [24000/60000 (40%)]\t1.550893\n",
      "Train Epoch: 8 [26000/60000 (43%)]\t1.553411\n",
      "Train Epoch: 8 [28000/60000 (47%)]\t1.512054\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t1.527763\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t1.523491\n",
      "Train Epoch: 8 [34000/60000 (57%)]\t1.495466\n",
      "Train Epoch: 8 [36000/60000 (60%)]\t1.557165\n",
      "Train Epoch: 8 [38000/60000 (63%)]\t1.504324\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t1.510279\n",
      "Train Epoch: 8 [42000/60000 (70%)]\t1.541301\n",
      "Train Epoch: 8 [44000/60000 (73%)]\t1.523618\n",
      "Train Epoch: 8 [46000/60000 (77%)]\t1.581631\n",
      "Train Epoch: 8 [48000/60000 (80%)]\t1.513266\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t1.520007\n",
      "Train Epoch: 8 [52000/60000 (87%)]\t1.495004\n",
      "Train Epoch: 8 [54000/60000 (90%)]\t1.540274\n",
      "Train Epoch: 8 [56000/60000 (93%)]\t1.531117\n",
      "Train Epoch: 8 [58000/60000 (97%)]\t1.506454\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy 9726/10000 (97%\n",
      ")\n",
      "Train Epoch: 9 [0/60000 (0%)]\t1.483276\n",
      "Train Epoch: 9 [2000/60000 (3%)]\t1.489355\n",
      "Train Epoch: 9 [4000/60000 (7%)]\t1.504518\n",
      "Train Epoch: 9 [6000/60000 (10%)]\t1.517712\n",
      "Train Epoch: 9 [8000/60000 (13%)]\t1.517023\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t1.525874\n",
      "Train Epoch: 9 [12000/60000 (20%)]\t1.514791\n",
      "Train Epoch: 9 [14000/60000 (23%)]\t1.566578\n",
      "Train Epoch: 9 [16000/60000 (27%)]\t1.510594\n",
      "Train Epoch: 9 [18000/60000 (30%)]\t1.497383\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t1.509921\n",
      "Train Epoch: 9 [22000/60000 (37%)]\t1.548242\n",
      "Train Epoch: 9 [24000/60000 (40%)]\t1.518170\n",
      "Train Epoch: 9 [26000/60000 (43%)]\t1.514296\n",
      "Train Epoch: 9 [28000/60000 (47%)]\t1.547225\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t1.516790\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t1.541654\n",
      "Train Epoch: 9 [34000/60000 (57%)]\t1.557939\n",
      "Train Epoch: 9 [36000/60000 (60%)]\t1.518122\n",
      "Train Epoch: 9 [38000/60000 (63%)]\t1.549965\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t1.522592\n",
      "Train Epoch: 9 [42000/60000 (70%)]\t1.535473\n",
      "Train Epoch: 9 [44000/60000 (73%)]\t1.524889\n",
      "Train Epoch: 9 [46000/60000 (77%)]\t1.548160\n",
      "Train Epoch: 9 [48000/60000 (80%)]\t1.543243\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t1.504216\n",
      "Train Epoch: 9 [52000/60000 (87%)]\t1.500324\n",
      "Train Epoch: 9 [54000/60000 (90%)]\t1.555419\n",
      "Train Epoch: 9 [56000/60000 (93%)]\t1.527545\n",
      "Train Epoch: 9 [58000/60000 (97%)]\t1.539774\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy 9735/10000 (97%\n",
      ")\n",
      "Train Epoch: 10 [0/60000 (0%)]\t1.523908\n",
      "Train Epoch: 10 [2000/60000 (3%)]\t1.557248\n",
      "Train Epoch: 10 [4000/60000 (7%)]\t1.584094\n",
      "Train Epoch: 10 [6000/60000 (10%)]\t1.526438\n",
      "Train Epoch: 10 [8000/60000 (13%)]\t1.508368\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t1.515880\n",
      "Train Epoch: 10 [12000/60000 (20%)]\t1.482636\n",
      "Train Epoch: 10 [14000/60000 (23%)]\t1.490365\n",
      "Train Epoch: 10 [16000/60000 (27%)]\t1.521477\n",
      "Train Epoch: 10 [18000/60000 (30%)]\t1.524310\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t1.497289\n",
      "Train Epoch: 10 [22000/60000 (37%)]\t1.521655\n",
      "Train Epoch: 10 [24000/60000 (40%)]\t1.537750\n",
      "Train Epoch: 10 [26000/60000 (43%)]\t1.504463\n",
      "Train Epoch: 10 [28000/60000 (47%)]\t1.500558\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t1.541631\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t1.522535\n",
      "Train Epoch: 10 [34000/60000 (57%)]\t1.520447\n",
      "Train Epoch: 10 [36000/60000 (60%)]\t1.545981\n",
      "Train Epoch: 10 [38000/60000 (63%)]\t1.481169\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t1.552467\n",
      "Train Epoch: 10 [42000/60000 (70%)]\t1.514691\n",
      "Train Epoch: 10 [44000/60000 (73%)]\t1.524578\n",
      "Train Epoch: 10 [46000/60000 (77%)]\t1.551289\n",
      "Train Epoch: 10 [48000/60000 (80%)]\t1.536154\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t1.509176\n",
      "Train Epoch: 10 [52000/60000 (87%)]\t1.525186\n",
      "Train Epoch: 10 [54000/60000 (90%)]\t1.500179\n",
      "Train Epoch: 10 [56000/60000 (93%)]\t1.554878\n",
      "Train Epoch: 10 [58000/60000 (97%)]\t1.505244\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy 9744/10000 (97%\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyder\\AppData\\Local\\Temp/ipykernel_4768/4106072696.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[0]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f\"Prediction: {prediction}\")\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
